<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Algorithms - Comp0010 Report Website</title><meta name="description" content="In this section we will mainly be examining algorithms that are either directly included in or is related to our chosen explainer library. We will also be covering alternative algorithms that are worth mentioning, but are not related to our explainer module or are ultimately&hellip;"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="./algorithms.html"><style>:root{--body-font:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen,Ubuntu,Cantarell,"Fira Sans","Droid Sans","Helvetica Neue",Arial,sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol";--heading-font:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen,Ubuntu,Cantarell,"Fira Sans","Droid Sans","Helvetica Neue",Arial,sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol";--logo-font:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen,Ubuntu,Cantarell,"Fira Sans","Droid Sans","Helvetica Neue",Arial,sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol";--menu-font:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen,Ubuntu,Cantarell,"Fira Sans","Droid Sans","Helvetica Neue",Arial,sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol"}</style><link rel="stylesheet" href="./assets/css/style.css?v=49f7729c0e61efe6d699137b011dbd7a"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"./algorithms.html"},"headline":"Algorithms","datePublished":"2021-03-22T16:55","dateModified":"2021-03-27T21:01","description":"In this section we will mainly be examining algorithms that are either directly included in or is related to our chosen explainer library. We will also be covering alternative algorithms that are worth mentioning, but are not related to our explainer module or are ultimately&hellip;","author":{"@type":"Person","name":"James Chang"},"publisher":{"@type":"Organization","name":"James Chang"}}</script></head><body><div class="site-container"><header class="top" id="js-header"><a class="logo" href="./">Comp0010 Report Website</a></header><main><article class="post"><div class="hero"><header class="hero__content"><div class="wrapper"><h1>Algorithms</h1></div></header></div><div class="wrapper post__entry"><p>In this section we will mainly be examining algorithms that are either directly included in or is related to our chosen explainer library. We will also be covering alternative algorithms that are worth mentioning, but are not related to our explainer module or are ultimately not used in our project.</p><h3>Explainer Algorithm</h3><h6>LIME</h6><p><span style="font-weight: 400;">LIME (Local Interpretable Model-agnostic Explanations) is a Local Surrogate algorithm, one which explains individual predictions of a machine learning model. In practice, this algorithm will look at the reasons that a specific point of data was predicted as it was, rather than the factors that cause a model to act in a certain way for predictions in general. </span></p><figure class="post__image post__image--center"><img loading="lazy" src="./media/posts/10/LIME-algorithm.png" sizes="(max-width: 48em) 100vw, 768px" srcset="./media/posts/10/responsive/LIME-algorithm-xs.png 300w, ./media/posts/10/responsive/LIME-algorithm-sm.png 480w, ./media/posts/10/responsive/LIME-algorithm-md.png 768w, ./media/posts/10/responsive/LIME-algorithm-lg.png 1024w, ./media/posts/10/responsive/LIME-algorithm-xl.png 1360w, ./media/posts/10/responsive/LIME-algorithm-2xl.png 1600w" alt="" width="500" height="68"><figcaption><p class="p1"><i>The maths behind Local Surrogate models[1]</i></p></figcaption></figure><p><span style="font-weight: 400;">The way LIME predicts these is by generating a new dataset based on the original dataset provided. It modifies the data points used in the original model and trains a surrogate model on the new dataset. It then attempts to predict the same values that the original model did and it compares the results. This method of explaining AI is extremely useful when looking at image based datasets, however its results are not as good when working on tabular datasets. Though the team eventually decided against using this algorithm, part of its features are present in the SHAP algorithm mentioned below.</span></p><h6>Shapley Values</h6><p><span style="font-weight: 400;">Shapely Values as an explanation for AI models is a method born from game theory. It takes a data point and assigns each feature as a player, then attempts to distribute the summation of the predicted value across all the players to show how much each feature contributed to the overall predicted value. It compares the model’s data point prediction against the average value predictions, and calculates the distribution by finding the average contribution of each feature. As a very smart and robust algorithm, it is incorporated into the SHAP algorithm which the team eventually decided to use.</span></p><h6>SHAP</h6><p><span style="font-weight: 400;">SHAP (SHapley Additive exPlanations) is an algorithm that works by estimating the Shapely Values for every point within the dataset in the same way as mentioned above. It uses the feature editing function that LIME does in order to gather more data for the dataset, then uses the summation of all the calculated values to get a global explanation.</span></p><figure class="post__image post__image--center"><img loading="lazy" src="./media/posts/10/SHAP-function.png" sizes="(max-width: 48em) 100vw, 768px" srcset="./media/posts/10/responsive/SHAP-function-xs.png 300w, ./media/posts/10/responsive/SHAP-function-sm.png 480w, ./media/posts/10/responsive/SHAP-function-md.png 768w, ./media/posts/10/responsive/SHAP-function-lg.png 1024w, ./media/posts/10/responsive/SHAP-function-xl.png 1360w, ./media/posts/10/responsive/SHAP-function-2xl.png 1600w" alt="" width="300" height="104"><figcaption><p class="p1"><i>The maths behind calculating SHAP values[1]</i></p></figcaption></figure><p><span style="font-weight: 400;">SHAP allows for both local explanations on specific data points and global explanations on a model's general prediction. It uses ideas from both Local Surrogate Models and Game Theory. It combines the best methods from previously created algorithms in order to get an all encompassing algorithm. It contains the SHAP Kernel explainer for lightweight kernel-based explanations, the SHAP Deep explainer for explaining deep neural networks, the SHAP Tree explainer for tree based models and the SHAP Linear for linear models. Essentially, SHAP is a comprehensive tool with enhanced features of all other methods we have looked into so far. Being an open-source library also means we could use it within the product for all explanations.</span></p><p><span style="font-weight: 400;">SHAP was utilised in the project within the Interpret-Community SDK. This allows for dynamic allocation of different SHAP explainers for targeted models, and also makes generating interactive graphs based on the explanation possible. This feature saved precious time for the team by eliminating the need to reimplement pre-built functionality.</span></p><h3>Other Algorithms</h3><h6 class="p1">PFI</h6><p>An extra algorithm worth mentioning is the PFI (Permutation Feature Importance) algorithm. It is an explanation model that works by changing a feature of a data point and measuring the increase in prediction error after the change in order to separate the feature from the outcome. The team considered using it for its ease of implementation, but eventually decided against it as method is quite simple and not as robust as other readily available methods.</p><h6>Django</h6><p class="p1">Other than explainer algorithms, we utilised Django for its security protocol as it ensured that developers don’t commit any mistakes related to security. Some of the common mistakes include SQL injection, cross-site request forgery, clickjacking and cross-site scripting. To manage usernames and passwords effectively, the user authentication system is the key. It works in a way that includes dozens of extras to help with user authentication, site maps, content administration, RSS feeds and much more such things. These aspects help in carrying out the web development process completely.</p><p class="p2">In order to keep data-sensitive information like public datasets secure, we opted for Django’s PBKDF2 and bcrypt algorithms, keeping the encrypted dataset password key in database_encryption column on PostgreSQL. bcrypt is able to mitigate those kinds of attacks by combining the expensive key setup phase of Blowfish with a variable number of iterations to increase the workload and duration of hash calculations. The largest benefit of bcrypt is that, over time, the iteration count can be increased to make it slower allowing bcrypt to scale with computing power.</p><figure class="post__image post__image--center"><img loading="lazy" src="./media/posts/10/Django-algorithm.png" sizes="(max-width: 48em) 100vw, 768px" srcset="./media/posts/10/responsive/Django-algorithm-xs.png 300w, ./media/posts/10/responsive/Django-algorithm-sm.png 480w, ./media/posts/10/responsive/Django-algorithm-md.png 768w, ./media/posts/10/responsive/Django-algorithm-lg.png 1024w, ./media/posts/10/responsive/Django-algorithm-xl.png 1360w, ./media/posts/10/responsive/Django-algorithm-2xl.png 1600w" alt="" width="400" height="207"><figcaption>The bcrypt algorithm[2]</figcaption></figure><h3>Conclusion</h3><p>Our choice of algorithms is largely focused around functionality with versatility in mind. We chose to use SHAP algorithm supported by the Interpret Community SDK mainly because it offers great functionality on the most popular machine learning models. Other algorithms like PFI are more versatile, however they are functionally weaker in comparison.</p><h3>References</h3><p>[1]   C. Molnar, "Interpretable Machine Learning: A Guide for Making Black Box Models<br>        Explainable,<em>"</em>  Feb. 24, 2019. [Online]. Available: <br>        <a href="https://christophm.github.io/interpretable-ml-book/">https://christophm.github.io/interpretable-ml-book/</a>. [Accessed Mar. 12, 2021].</p><p>[2]   Provos, Niels; Mazières, David; Talan Jason Sutton 2012 (1999), "A Future-<br>        Adaptable Password Scheme," <i>Proceedings of 1999 USENIX Annual Technical<br>        Conference</i>, p.85, Apr. 28, 1999. [Online]. Available:<br><a href="https://www.usenix.org/legacy/events/usenix99/provos/provos_html/node5.html">        https://www.usenix.org/legacy/events/usenix99/provos/provos_html/node5.html</a>.<br>        [Accessed Mar. 17, 2021]</p></div></article><nav class="post__nav"><div class="post__nav-inner"><div class="post__nav-prev"><svg width="1.041em" height="0.416em" aria-hidden="true"><use xlink:href="./assets/svg/svg-map.svg#arrow-prev"/></svg> <a href="./research.html" class="invert post__nav-link" rel="prev"><span>Previous</span> Research</a></div><div class="post__nav-next"><a href="./ui-design.html" class="invert post__nav-link" rel="next"><span>Next</span> UI Design </a><svg width="1.041em" height="0.416em" aria-hidden="true"><use xlink:href="./assets/svg/svg-map.svg#arrow-next"/></svg></div></div></nav></main><footer class="footer"><div class="footer__copyright"><p>Powered by <a href="https://getpublii.com" target="_blank" rel="nofollow noopener">Publii</a></p></div></footer></div><script>window.publiiThemeMenuConfig = {    
        mobileMenuMode: 'sidebar',
        animationSpeed: 300,
        submenuWidth: 'auto',
        doubleClickTime: 500,
        mobileMenuExpandableSubmenus: true, 
        relatedContainerForOverlayMenuSelector: '.top',
   };</script><script defer="defer" src="./assets/js/scripts.min.js?v=f4c4d35432d0e17d212f2fae4e0f8247"></script><script>var images = document.querySelectorAll('img[loading]');

        for (var i = 0; i < images.length; i++) {
            if (images[i].complete) {
                images[i].classList.add('is-loaded');
            } else {
                images[i].addEventListener('load', function () {
                    this.classList.add('is-loaded');
                }, false);
            }
        }</script></body></html>